# === Hardware Configuration ===
accelerator = "cuda"          # "cpu", "gpu", "mps", "auto"
devices = [0]                  # Number of devices to use (1 for single GPU)]
precision = "bf16"             # "16", "bf16", "32", "16-mixed"

# === Training Configuration ===
max_epochs = 100                # Maximum training epochs
batch_size = 16384               # Training batch size
approach = "adamw_warmup_cosine_annealing_restarts"    # "sgd_simple", "adamw_simple", "adamw_cosine"

# === Data Loading ===
num_workers = 10              # Data loader workers
pin_memory = true            # Pin memory for faster GPU transfer
persistent_workers = false   # Keep workers alive between epochs

# === Training Control ===
accumulate_grad_batches = 1  # Gradient accumulation batches
log_every_n_steps = 1        # Log metrics every N steps
check_val_every_n_epoch = 1  # Validate every N epochs
